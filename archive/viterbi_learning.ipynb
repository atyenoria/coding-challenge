{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm: Learning and Testing\n",
    "\n",
    "This notebook provides an interactive learning experience for the Viterbi algorithm, including:\n",
    "- Theory and intuition behind the algorithm\n",
    "- Step-by-step implementation\n",
    "- Practical exercises to test your understanding\n",
    "- Visualization of the decoding process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## What is the Viterbi Algorithm?\n",
    "\n",
    "The Viterbi algorithm is a **dynamic programming** algorithm used to find the most likely sequence of hidden states in a Hidden Markov Model (HMM). It's widely used in:\n",
    "\n",
    "- **Speech Recognition**: Decoding spoken words from acoustic signals\n",
    "- **Part-of-Speech Tagging**: Finding the most likely sequence of POS tags\n",
    "- **DNA Sequence Analysis**: Identifying gene regions\n",
    "- **Error Correction**: Decoding convolutional codes\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **States**: Hidden states we want to discover\n",
    "2. **Observations**: What we can actually see/measure\n",
    "3. **Transition Probabilities**: P(next_state | current_state)\n",
    "4. **Emission Probabilities**: P(observation | state)\n",
    "5. **Initial Probabilities**: P(starting in each state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Hidden Markov Model (HMM) Class\n",
    "\n",
    "First, let's define a simple HMM class that stores all the parameters we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    \"\"\"A simple Hidden Markov Model implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, states: List[str], observations: List[str],\n",
    "                 start_prob: Dict[str, float],\n",
    "                 trans_prob: Dict[str, Dict[str, float]],\n",
    "                 emit_prob: Dict[str, Dict[str, float]]):\n",
    "        \"\"\"\n",
    "        Initialize the HMM.\n",
    "        \n",
    "        Args:\n",
    "            states: List of hidden states\n",
    "            observations: List of possible observations\n",
    "            start_prob: Initial state probabilities\n",
    "            trans_prob: State transition probabilities\n",
    "            emit_prob: Emission probabilities\n",
    "        \"\"\"\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.start_prob = start_prob\n",
    "        self.trans_prob = trans_prob\n",
    "        self.emit_prob = emit_prob\n",
    "        \n",
    "        # Create index mappings\n",
    "        self.state_idx = {s: i for i, s in enumerate(states)}\n",
    "        self.obs_idx = {o: i for i, o in enumerate(observations)}\n",
    "    \n",
    "    def get_start_prob(self, state: str) -> float:\n",
    "        return self.start_prob.get(state, 0.0)\n",
    "    \n",
    "    def get_trans_prob(self, from_state: str, to_state: str) -> float:\n",
    "        return self.trans_prob.get(from_state, {}).get(to_state, 0.0)\n",
    "    \n",
    "    def get_emit_prob(self, state: str, observation: str) -> float:\n",
    "        return self.emit_prob.get(state, {}).get(observation, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Example: Weather and Activities\n",
    "\n",
    "Let's use a classic example: inferring the weather (hidden states) from observed activities.\n",
    "\n",
    "- **Hidden States**: Sunny, Rainy\n",
    "- **Observations**: Walk, Shop, Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Weather HMM\n",
    "states = [\"Sunny\", \"Rainy\"]\n",
    "observations = [\"Walk\", \"Shop\", \"Clean\"]\n",
    "\n",
    "# Initial probabilities\n",
    "start_prob = {\n",
    "    \"Sunny\": 0.6,\n",
    "    \"Rainy\": 0.4\n",
    "}\n",
    "\n",
    "# Transition probabilities\n",
    "trans_prob = {\n",
    "    \"Sunny\": {\"Sunny\": 0.7, \"Rainy\": 0.3},\n",
    "    \"Rainy\": {\"Sunny\": 0.4, \"Rainy\": 0.6}\n",
    "}\n",
    "\n",
    "# Emission probabilities\n",
    "emit_prob = {\n",
    "    \"Sunny\": {\"Walk\": 0.6, \"Shop\": 0.3, \"Clean\": 0.1},\n",
    "    \"Rainy\": {\"Walk\": 0.1, \"Shop\": 0.4, \"Clean\": 0.5}\n",
    "}\n",
    "\n",
    "weather_hmm = HiddenMarkovModel(states, observations, start_prob, trans_prob, emit_prob)\n",
    "print(\"HMM Created Successfully!\")\n",
    "print(f\"States: {weather_hmm.states}\")\n",
    "print(f\"Observations: {weather_hmm.observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## The Viterbi Algorithm: Step by Step\n",
    "\n",
    "The algorithm works in two phases:\n",
    "\n",
    "### Phase 1: Forward Pass (Trellis Construction)\n",
    "For each time step t and state s:\n",
    "```\n",
    "V[t][s] = max over all previous states s' of:\n",
    "    V[t-1][s'] * P(s|s') * P(observation[t]|s)\n",
    "```\n",
    "\n",
    "### Phase 2: Backtracking\n",
    "Trace back through the stored pointers to find the optimal path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(hmm: HiddenMarkovModel, obs_sequence: List[str], \n",
    "            verbose: bool = False) -> Tuple[List[str], float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run the Viterbi algorithm to find the most likely state sequence.\n",
    "    \n",
    "    Args:\n",
    "        hmm: The Hidden Markov Model\n",
    "        obs_sequence: List of observations\n",
    "        verbose: If True, print step-by-step details\n",
    "        \n",
    "    Returns:\n",
    "        best_path: Most likely sequence of states\n",
    "        best_prob: Probability of the best path\n",
    "        trellis: The Viterbi trellis (for visualization)\n",
    "    \"\"\"\n",
    "    n_states = len(hmm.states)\n",
    "    n_obs = len(obs_sequence)\n",
    "    \n",
    "    # Initialize trellis and backpointer\n",
    "    trellis = np.zeros((n_states, n_obs))\n",
    "    backpointer = np.zeros((n_states, n_obs), dtype=int)\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 1: Initialization (t=0)\n",
    "    # ========================================\n",
    "    if verbose:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"STEP 1: Initialization for observation '{obs_sequence[0]}'\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    for i, state in enumerate(hmm.states):\n",
    "        start_p = hmm.get_start_prob(state)\n",
    "        emit_p = hmm.get_emit_prob(state, obs_sequence[0])\n",
    "        trellis[i, 0] = start_p * emit_p\n",
    "        backpointer[i, 0] = -1  # No previous state\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  State '{state}': P(start) * P('{obs_sequence[0]}') = {start_p} * {emit_p} = {trellis[i, 0]:.4f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 2: Recursion (t=1 to T-1)\n",
    "    # ========================================\n",
    "    for t in range(1, n_obs):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"STEP 2.{t}: Processing observation '{obs_sequence[t]}' at time {t}\")\n",
    "            print(\"=\" * 50)\n",
    "        \n",
    "        for j, curr_state in enumerate(hmm.states):\n",
    "            max_prob = 0\n",
    "            max_state = 0\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n  Computing for current state '{curr_state}':\")\n",
    "            \n",
    "            for i, prev_state in enumerate(hmm.states):\n",
    "                trans_p = hmm.get_trans_prob(prev_state, curr_state)\n",
    "                prob = trellis[i, t-1] * trans_p\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"    From '{prev_state}': V[t-1] * P(trans) = {trellis[i, t-1]:.4f} * {trans_p} = {prob:.4f}\")\n",
    "                \n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = i\n",
    "            \n",
    "            emit_p = hmm.get_emit_prob(curr_state, obs_sequence[t])\n",
    "            trellis[j, t] = max_prob * emit_p\n",
    "            backpointer[j, t] = max_state\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"    Best from '{hmm.states[max_state]}': {max_prob:.4f} * P(emit)={emit_p} = {trellis[j, t]:.4f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 3: Termination\n",
    "    # ========================================\n",
    "    best_last_state = np.argmax(trellis[:, -1])\n",
    "    best_prob = trellis[best_last_state, -1]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(\"STEP 3: Termination\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"  Best final state: '{hmm.states[best_last_state]}' with probability {best_prob:.6f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 4: Backtracking\n",
    "    # ========================================\n",
    "    best_path = [hmm.states[best_last_state]]\n",
    "    current_state = best_last_state\n",
    "    \n",
    "    for t in range(n_obs - 1, 0, -1):\n",
    "        current_state = backpointer[current_state, t]\n",
    "        best_path.insert(0, hmm.states[current_state])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(\"STEP 4: Backtracking\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"  Best path: {' -> '.join(best_path)}\")\n",
    "    \n",
    "    return best_path, best_prob, trellis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Test the Viterbi Algorithm\n",
    "\n",
    "Let's trace through the algorithm with a sample observation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test observation sequence\n",
    "obs_sequence = [\"Walk\", \"Shop\", \"Clean\"]\n",
    "\n",
    "print(\"Running Viterbi Algorithm\")\n",
    "print(f\"Observations: {obs_sequence}\\n\")\n",
    "\n",
    "best_path, best_prob, trellis = viterbi(weather_hmm, obs_sequence, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Most likely weather sequence: {best_path}\")\n",
    "print(f\"Probability: {best_prob:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Visualization: Viterbi Trellis\n",
    "\n",
    "Visualize the trellis to see how probabilities propagate through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trellis(hmm: HiddenMarkovModel, obs_sequence: List[str], \n",
    "                      trellis: np.ndarray, best_path: List[str]):\n",
    "    \"\"\"Visualize the Viterbi trellis as a heatmap with the best path highlighted.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(trellis, annot=True, fmt=\".4f\", cmap=\"YlOrRd\",\n",
    "                xticklabels=obs_sequence, yticklabels=hmm.states,\n",
    "                ax=ax, cbar_kws={'label': 'Probability'})\n",
    "    \n",
    "    # Highlight best path\n",
    "    for t, state in enumerate(best_path):\n",
    "        state_idx = hmm.state_idx[state]\n",
    "        ax.add_patch(plt.Rectangle((t, state_idx), 1, 1, \n",
    "                                    fill=False, edgecolor='blue', linewidth=3))\n",
    "    \n",
    "    ax.set_xlabel(\"Observations (Time)\")\n",
    "    ax.set_ylabel(\"Hidden States\")\n",
    "    ax.set_title(\"Viterbi Trellis (Blue boxes = Best Path)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_trellis(weather_hmm, obs_sequence, trellis, best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercises: Test Your Understanding\n",
    "\n",
    "Complete the following exercises to test your understanding of the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Exercise 1: Manual Calculation\n",
    "\n",
    "Given the observation sequence `[\"Clean\", \"Clean\"]`, manually calculate the Viterbi probabilities.\n",
    "\n",
    "Fill in the `???` values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Fill in your calculations\n",
    "\n",
    "# Time t=0, Observation=\"Clean\"\n",
    "# V[Sunny, 0] = P(start=Sunny) * P(Clean|Sunny) = 0.6 * 0.1 = ???\n",
    "# V[Rainy, 0] = P(start=Rainy) * P(Clean|Rainy) = 0.4 * 0.5 = ???\n",
    "\n",
    "v_sunny_0 = None  # Replace with your answer\n",
    "v_rainy_0 = None  # Replace with your answer\n",
    "\n",
    "# Time t=1, Observation=\"Clean\"\n",
    "# V[Sunny, 1] = max(V[Sunny,0]*P(S->S), V[Rainy,0]*P(R->S)) * P(Clean|Sunny)\n",
    "# V[Rainy, 1] = max(V[Sunny,0]*P(S->R), V[Rainy,0]*P(R->R)) * P(Clean|Rainy)\n",
    "\n",
    "v_sunny_1 = None  # Replace with your answer\n",
    "v_rainy_1 = None  # Replace with your answer\n",
    "\n",
    "# What is the most likely state sequence?\n",
    "predicted_sequence = None  # Replace with [\"???\", \"???\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answers\n",
    "def check_exercise_1(v_sunny_0, v_rainy_0, v_sunny_1, v_rainy_1, predicted_sequence):\n",
    "    obs = [\"Clean\", \"Clean\"]\n",
    "    correct_path, correct_prob, correct_trellis = viterbi(weather_hmm, obs, verbose=False)\n",
    "    \n",
    "    print(\"Checking your answers...\\n\")\n",
    "    \n",
    "    all_correct = True\n",
    "    \n",
    "    # Check t=0\n",
    "    if v_sunny_0 is not None and abs(v_sunny_0 - correct_trellis[0, 0]) < 0.001:\n",
    "        print(\"V[Sunny, 0]: CORRECT\")\n",
    "    else:\n",
    "        print(f\"V[Sunny, 0]: INCORRECT (Expected: {correct_trellis[0, 0]})\")\n",
    "        all_correct = False\n",
    "    \n",
    "    if v_rainy_0 is not None and abs(v_rainy_0 - correct_trellis[1, 0]) < 0.001:\n",
    "        print(\"V[Rainy, 0]: CORRECT\")\n",
    "    else:\n",
    "        print(f\"V[Rainy, 0]: INCORRECT (Expected: {correct_trellis[1, 0]})\")\n",
    "        all_correct = False\n",
    "    \n",
    "    # Check t=1\n",
    "    if v_sunny_1 is not None and abs(v_sunny_1 - correct_trellis[0, 1]) < 0.001:\n",
    "        print(\"V[Sunny, 1]: CORRECT\")\n",
    "    else:\n",
    "        print(f\"V[Sunny, 1]: INCORRECT (Expected: {correct_trellis[0, 1]})\")\n",
    "        all_correct = False\n",
    "    \n",
    "    if v_rainy_1 is not None and abs(v_rainy_1 - correct_trellis[1, 1]) < 0.001:\n",
    "        print(\"V[Rainy, 1]: CORRECT\")\n",
    "    else:\n",
    "        print(f\"V[Rainy, 1]: INCORRECT (Expected: {correct_trellis[1, 1]})\")\n",
    "        all_correct = False\n",
    "    \n",
    "    # Check sequence\n",
    "    if predicted_sequence == correct_path:\n",
    "        print(\"Predicted sequence: CORRECT\")\n",
    "    else:\n",
    "        print(f\"Predicted sequence: INCORRECT (Expected: {correct_path})\")\n",
    "        all_correct = False\n",
    "    \n",
    "    if all_correct:\n",
    "        print(\"\\nExcellent! All answers are correct!\")\n",
    "    else:\n",
    "        print(\"\\nSome answers need correction. Try again!\")\n",
    "\n",
    "# Uncomment the line below after filling in your answers\n",
    "# check_exercise_1(v_sunny_0, v_rainy_0, v_sunny_1, v_rainy_1, predicted_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Exercise 2: Implement Log-Space Viterbi\n",
    "\n",
    "The standard Viterbi can suffer from numerical underflow with long sequences. Implement a log-space version that uses log probabilities instead.\n",
    "\n",
    "**Hint**: \n",
    "- Replace multiplication with addition: `log(a*b) = log(a) + log(b)`\n",
    "- Use `np.log()` for converting probabilities\n",
    "- Handle zero probabilities with `-np.inf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_log(hmm: HiddenMarkovModel, obs_sequence: List[str]) -> Tuple[List[str], float]:\n",
    "    \"\"\"\n",
    "    Log-space Viterbi algorithm.\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    \n",
    "    Args:\n",
    "        hmm: The Hidden Markov Model\n",
    "        obs_sequence: List of observations\n",
    "        \n",
    "    Returns:\n",
    "        best_path: Most likely sequence of states\n",
    "        best_log_prob: Log probability of the best path\n",
    "    \"\"\"\n",
    "    n_states = len(hmm.states)\n",
    "    n_obs = len(obs_sequence)\n",
    "    \n",
    "    # Initialize with log probabilities\n",
    "    trellis = np.full((n_states, n_obs), -np.inf)\n",
    "    backpointer = np.zeros((n_states, n_obs), dtype=int)\n",
    "    \n",
    "    # TODO: Implement initialization (t=0)\n",
    "    # Hint: trellis[i, 0] = log(start_prob) + log(emit_prob)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "    \n",
    "    # TODO: Implement recursion (t=1 to T-1)\n",
    "    # Hint: Use addition instead of multiplication\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "    \n",
    "    # TODO: Implement termination and backtracking\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    best_path = []\n",
    "    best_log_prob = 0.0\n",
    "    \n",
    "    return best_path, best_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your log-space implementation\n",
    "def test_viterbi_log():\n",
    "    obs = [\"Walk\", \"Shop\", \"Clean\"]\n",
    "    \n",
    "    # Get reference result\n",
    "    ref_path, ref_prob, _ = viterbi(weather_hmm, obs)\n",
    "    \n",
    "    # Get your result\n",
    "    your_path, your_log_prob = viterbi_log(weather_hmm, obs)\n",
    "    \n",
    "    print(f\"Reference path: {ref_path}\")\n",
    "    print(f\"Your path: {your_path}\")\n",
    "    print(f\"Reference log prob: {np.log(ref_prob):.6f}\")\n",
    "    print(f\"Your log prob: {your_log_prob:.6f}\")\n",
    "    \n",
    "    if your_path == ref_path and abs(your_log_prob - np.log(ref_prob)) < 0.001:\n",
    "        print(\"\\nCongratulations! Your implementation is correct!\")\n",
    "    else:\n",
    "        print(\"\\nNot quite right. Check your implementation.\")\n",
    "\n",
    "# Uncomment after implementing\n",
    "# test_viterbi_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Exercise 3: Part-of-Speech Tagging\n",
    "\n",
    "Create an HMM for Part-of-Speech tagging and use Viterbi to tag a sentence.\n",
    "\n",
    "**Task**: Define an HMM with:\n",
    "- States: `[\"NOUN\", \"VERB\", \"DET\", \"ADJ\"]`\n",
    "- Some sample words and their emission probabilities\n",
    "- Reasonable transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create a POS tagging HMM\n",
    "\n",
    "pos_states = [\"NOUN\", \"VERB\", \"DET\", \"ADJ\"]\n",
    "words = [\"the\", \"cat\", \"sat\", \"big\", \"dog\", \"runs\", \"a\", \"happy\"]\n",
    "\n",
    "# TODO: Define start probabilities\n",
    "# Hint: Sentences often start with determiners or nouns\n",
    "pos_start_prob = {\n",
    "    \"NOUN\": None,  # Fill in\n",
    "    \"VERB\": None,  # Fill in\n",
    "    \"DET\": None,   # Fill in\n",
    "    \"ADJ\": None    # Fill in\n",
    "}\n",
    "\n",
    "# TODO: Define transition probabilities\n",
    "# Hint: Think about what typically follows each POS\n",
    "pos_trans_prob = {\n",
    "    \"NOUN\": {\"NOUN\": None, \"VERB\": None, \"DET\": None, \"ADJ\": None},\n",
    "    \"VERB\": {\"NOUN\": None, \"VERB\": None, \"DET\": None, \"ADJ\": None},\n",
    "    \"DET\": {\"NOUN\": None, \"VERB\": None, \"DET\": None, \"ADJ\": None},\n",
    "    \"ADJ\": {\"NOUN\": None, \"VERB\": None, \"DET\": None, \"ADJ\": None}\n",
    "}\n",
    "\n",
    "# TODO: Define emission probabilities\n",
    "# Hint: \"the\", \"a\" -> DET, \"cat\", \"dog\" -> NOUN, etc.\n",
    "pos_emit_prob = {\n",
    "    \"NOUN\": {w: None for w in words},\n",
    "    \"VERB\": {w: None for w in words},\n",
    "    \"DET\": {w: None for w in words},\n",
    "    \"ADJ\": {w: None for w in words}\n",
    "}\n",
    "\n",
    "# Uncomment after filling in the probabilities\n",
    "# pos_hmm = HiddenMarkovModel(pos_states, words, pos_start_prob, pos_trans_prob, pos_emit_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your POS tagger\n",
    "def test_pos_tagger():\n",
    "    sentences = [\n",
    "        [\"the\", \"cat\", \"runs\"],\n",
    "        [\"a\", \"big\", \"dog\", \"sat\"],\n",
    "        [\"the\", \"happy\", \"cat\"]\n",
    "    ]\n",
    "    \n",
    "    print(\"POS Tagging Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        path, prob, _ = viterbi(pos_hmm, sentence)\n",
    "        print(f\"\\nSentence: {' '.join(sentence)}\")\n",
    "        print(f\"POS Tags: {' '.join(path)}\")\n",
    "        print(f\"Tagged: {' '.join(f'{w}/{t}' for w, t in zip(sentence, path))}\")\n",
    "\n",
    "# Uncomment after creating the POS HMM\n",
    "# test_pos_tagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Exercise 4: Compare Viterbi with Greedy Decoding\n",
    "\n",
    "Implement a greedy decoder that picks the most likely state at each time step independently (without considering the path). Compare the results with Viterbi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(hmm: HiddenMarkovModel, obs_sequence: List[str]) -> Tuple[List[str], float]:\n",
    "    \"\"\"\n",
    "    Greedy decoder that picks the most likely state at each step.\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    \n",
    "    For each observation, pick the state with highest:\n",
    "    P(observation | state) * P(state)\n",
    "    \n",
    "    This ignores transition probabilities between states!\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return path, 0.0  # Return path and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Viterbi vs Greedy\n",
    "def compare_decoders():\n",
    "    test_sequences = [\n",
    "        [\"Walk\", \"Walk\", \"Walk\"],\n",
    "        [\"Clean\", \"Clean\", \"Clean\"],\n",
    "        [\"Walk\", \"Shop\", \"Clean\"],\n",
    "        [\"Clean\", \"Walk\", \"Shop\", \"Walk\"]\n",
    "    ]\n",
    "    \n",
    "    print(\"Comparison: Viterbi vs Greedy Decoding\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for obs in test_sequences:\n",
    "        viterbi_path, viterbi_prob, _ = viterbi(weather_hmm, obs)\n",
    "        greedy_path, greedy_prob = greedy_decode(weather_hmm, obs)\n",
    "        \n",
    "        print(f\"\\nObservations: {obs}\")\n",
    "        print(f\"Viterbi: {viterbi_path} (prob: {viterbi_prob:.6f})\")\n",
    "        print(f\"Greedy:  {greedy_path} (prob: {greedy_prob:.6f})\")\n",
    "        print(f\"Same result: {viterbi_path == greedy_path}\")\n",
    "\n",
    "# Uncomment after implementing greedy_decode\n",
    "# compare_decoders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions\n",
    "\n",
    "Run the cells below to see the solutions (try the exercises first!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Exercise 1\n",
    "def show_solution_1():\n",
    "    print(\"Exercise 1 Solution:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nTime t=0, Observation='Clean':\")\n",
    "    print(\"V[Sunny, 0] = 0.6 * 0.1 = 0.06\")\n",
    "    print(\"V[Rainy, 0] = 0.4 * 0.5 = 0.20\")\n",
    "    print(\"\\nTime t=1, Observation='Clean':\")\n",
    "    print(\"V[Sunny, 1] = max(0.06*0.7, 0.20*0.4) * 0.1 = max(0.042, 0.08) * 0.1 = 0.008\")\n",
    "    print(\"V[Rainy, 1] = max(0.06*0.3, 0.20*0.6) * 0.5 = max(0.018, 0.12) * 0.5 = 0.060\")\n",
    "    print(\"\\nBest path: ['Rainy', 'Rainy']\")\n",
    "    \n",
    "    # Verify\n",
    "    obs = [\"Clean\", \"Clean\"]\n",
    "    path, prob, _ = viterbi(weather_hmm, obs)\n",
    "    print(f\"\\nVerification: {path} with prob {prob:.6f}\")\n",
    "\n",
    "# Uncomment to see solution\n",
    "# show_solution_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Exercise 2: Log-space Viterbi\n",
    "def viterbi_log_solution(hmm: HiddenMarkovModel, obs_sequence: List[str]) -> Tuple[List[str], float]:\n",
    "    \"\"\"Log-space Viterbi algorithm - Solution.\"\"\"\n",
    "    n_states = len(hmm.states)\n",
    "    n_obs = len(obs_sequence)\n",
    "    \n",
    "    trellis = np.full((n_states, n_obs), -np.inf)\n",
    "    backpointer = np.zeros((n_states, n_obs), dtype=int)\n",
    "    \n",
    "    # Initialization\n",
    "    for i, state in enumerate(hmm.states):\n",
    "        start_p = hmm.get_start_prob(state)\n",
    "        emit_p = hmm.get_emit_prob(state, obs_sequence[0])\n",
    "        if start_p > 0 and emit_p > 0:\n",
    "            trellis[i, 0] = np.log(start_p) + np.log(emit_p)\n",
    "    \n",
    "    # Recursion\n",
    "    for t in range(1, n_obs):\n",
    "        for j, curr_state in enumerate(hmm.states):\n",
    "            max_log_prob = -np.inf\n",
    "            max_state = 0\n",
    "            \n",
    "            for i, prev_state in enumerate(hmm.states):\n",
    "                trans_p = hmm.get_trans_prob(prev_state, curr_state)\n",
    "                if trans_p > 0:\n",
    "                    log_prob = trellis[i, t-1] + np.log(trans_p)\n",
    "                    if log_prob > max_log_prob:\n",
    "                        max_log_prob = log_prob\n",
    "                        max_state = i\n",
    "            \n",
    "            emit_p = hmm.get_emit_prob(curr_state, obs_sequence[t])\n",
    "            if emit_p > 0:\n",
    "                trellis[j, t] = max_log_prob + np.log(emit_p)\n",
    "            backpointer[j, t] = max_state\n",
    "    \n",
    "    # Termination\n",
    "    best_last_state = np.argmax(trellis[:, -1])\n",
    "    best_log_prob = trellis[best_last_state, -1]\n",
    "    \n",
    "    # Backtracking\n",
    "    best_path = [hmm.states[best_last_state]]\n",
    "    current_state = best_last_state\n",
    "    \n",
    "    for t in range(n_obs - 1, 0, -1):\n",
    "        current_state = backpointer[current_state, t]\n",
    "        best_path.insert(0, hmm.states[current_state])\n",
    "    \n",
    "    return best_path, best_log_prob\n",
    "\n",
    "# Uncomment to test solution\n",
    "# obs = [\"Walk\", \"Shop\", \"Clean\"]\n",
    "# path, log_prob = viterbi_log_solution(weather_hmm, obs)\n",
    "# print(f\"Path: {path}, Log Prob: {log_prob:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Exercise 4: Greedy Decoder\n",
    "def greedy_decode_solution(hmm: HiddenMarkovModel, obs_sequence: List[str]) -> Tuple[List[str], float]:\n",
    "    \"\"\"Greedy decoder - Solution.\"\"\"\n",
    "    path = []\n",
    "    total_prob = 1.0\n",
    "    \n",
    "    for t, obs in enumerate(obs_sequence):\n",
    "        best_state = None\n",
    "        best_prob = 0\n",
    "        \n",
    "        for state in hmm.states:\n",
    "            if t == 0:\n",
    "                prob = hmm.get_start_prob(state) * hmm.get_emit_prob(state, obs)\n",
    "            else:\n",
    "                # Use marginal probability (sum over previous states)\n",
    "                prob = hmm.get_emit_prob(state, obs)\n",
    "            \n",
    "            if prob > best_prob:\n",
    "                best_prob = prob\n",
    "                best_state = state\n",
    "        \n",
    "        path.append(best_state)\n",
    "        total_prob *= best_prob\n",
    "    \n",
    "    return path, total_prob\n",
    "\n",
    "# Test the solution\n",
    "def compare_decoders_solution():\n",
    "    test_sequences = [\n",
    "        [\"Walk\", \"Walk\", \"Walk\"],\n",
    "        [\"Clean\", \"Clean\", \"Clean\"],\n",
    "        [\"Walk\", \"Shop\", \"Clean\"],\n",
    "    ]\n",
    "    \n",
    "    print(\"Comparison: Viterbi vs Greedy Decoding (Solution)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for obs in test_sequences:\n",
    "        viterbi_path, viterbi_prob, _ = viterbi(weather_hmm, obs)\n",
    "        greedy_path, greedy_prob = greedy_decode_solution(weather_hmm, obs)\n",
    "        \n",
    "        print(f\"\\nObservations: {obs}\")\n",
    "        print(f\"Viterbi: {viterbi_path}\")\n",
    "        print(f\"Greedy:  {greedy_path}\")\n",
    "        print(f\"Same: {viterbi_path == greedy_path}\")\n",
    "\n",
    "# Uncomment to see solution\n",
    "# compare_decoders_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Viterbi Algorithm** finds the most likely sequence of hidden states given observations\n",
    "2. **Dynamic Programming** makes it efficient: O(S\u00b2 \u00d7 T) instead of O(S^T)\n",
    "3. **Log-space** implementation prevents numerical underflow\n",
    "4. **Viterbi vs Greedy**: Viterbi considers the entire path, greedy only local decisions\n",
    "\n",
    "### Common Applications:\n",
    "- Speech Recognition\n",
    "- Part-of-Speech Tagging\n",
    "- Named Entity Recognition\n",
    "- DNA Sequence Analysis\n",
    "- Error Correction in Communications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
